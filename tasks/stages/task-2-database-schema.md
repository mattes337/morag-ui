# Task 2: Database Schema Changes for Stage Outputs

## Overview

Design and implement database schema changes to support storing output files and metadata for each processing stage. This includes tracking stage status, storing file references, and maintaining processing history.

## Current Database Structure

Before making changes, we need to understand the current document storage structure:

```sql
-- Current Documents table (assumed structure)
CREATE TABLE documents (
  id VARCHAR(255) PRIMARY KEY,
  title VARCHAR(255),
  content TEXT,
  realm_id VARCHAR(255),
  created_at TIMESTAMP,
  updated_at TIMESTAMP,
  -- other existing fields
);
```

## Required Schema Changes

### 1. Document Processing Stages Table

Track the processing status and metadata for each stage of each document.

```sql
CREATE TABLE document_processing_stages (
  id VARCHAR(255) PRIMARY KEY,
  document_id VARCHAR(255) NOT NULL,
  stage_name ENUM(
    'markdown-conversion',
    'markdown-optimizer', 
    'chunker',
    'fact-generator',
    'ingestor'
  ) NOT NULL,
  status ENUM(
    'pending',
    'in_progress', 
    'completed',
    'failed',
    'skipped'
  ) NOT NULL DEFAULT 'pending',
  started_at TIMESTAMP NULL,
  completed_at TIMESTAMP NULL,
  error_message TEXT NULL,
  retry_count INT DEFAULT 0,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
  
  FOREIGN KEY (document_id) REFERENCES documents(id) ON DELETE CASCADE,
  UNIQUE KEY unique_document_stage (document_id, stage_name),
  INDEX idx_document_stages (document_id),
  INDEX idx_stage_status (stage_name, status)
);
```

### 2. Stage Output Files Table

Store references to output files generated by each stage.

```sql
CREATE TABLE stage_output_files (
  id VARCHAR(255) PRIMARY KEY,
  document_id VARCHAR(255) NOT NULL,
  stage_name ENUM(
    'markdown-conversion',
    'markdown-optimizer',
    'chunker', 
    'fact-generator',
    'ingestor'
  ) NOT NULL,
  file_type ENUM(
    'markdown',
    'optimized_markdown',
    'chunks_json',
    'facts_json', 
    'ingestion_json'
  ) NOT NULL,
  file_path VARCHAR(500) NOT NULL,
  file_size BIGINT,
  mime_type VARCHAR(100),
  checksum VARCHAR(64),
  metadata JSON,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  
  FOREIGN KEY (document_id) REFERENCES documents(id) ON DELETE CASCADE,
  INDEX idx_document_files (document_id),
  INDEX idx_stage_files (stage_name, file_type),
  UNIQUE KEY unique_document_stage_file (document_id, stage_name, file_type)
);
```

### 3. Processing Workflows Table

Track overall processing workflows and their configurations.

```sql
CREATE TABLE processing_workflows (
  id VARCHAR(255) PRIMARY KEY,
  document_id VARCHAR(255) NOT NULL,
  workflow_type ENUM('automatic', 'manual') NOT NULL DEFAULT 'manual',
  total_stages INT NOT NULL DEFAULT 5,
  completed_stages INT NOT NULL DEFAULT 0,
  current_stage ENUM(
    'markdown-conversion',
    'markdown-optimizer',
    'chunker',
    'fact-generator', 
    'ingestor',
    'completed'
  ),
  started_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  completed_at TIMESTAMP NULL,
  configuration JSON,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
  
  FOREIGN KEY (document_id) REFERENCES documents(id) ON DELETE CASCADE,
  INDEX idx_workflow_status (current_stage, workflow_type)
);
```

### 4. Stage Dependencies Table

Define stage dependencies and execution order.

```sql
CREATE TABLE stage_dependencies (
  id VARCHAR(255) PRIMARY KEY,
  stage_name ENUM(
    'markdown-conversion',
    'markdown-optimizer',
    'chunker',
    'fact-generator',
    'ingestor'
  ) NOT NULL,
  depends_on_stage ENUM(
    'markdown-conversion',
    'markdown-optimizer', 
    'chunker',
    'fact-generator',
    'ingestor'
  ),
  is_required BOOLEAN NOT NULL DEFAULT true,
  execution_order INT NOT NULL,
  
  UNIQUE KEY unique_dependency (stage_name, depends_on_stage),
  INDEX idx_stage_order (execution_order)
);
```

## Data Migration Strategy

### 1. Existing Documents

For existing documents in the system:

```sql
-- Create initial processing workflows for existing documents
INSERT INTO processing_workflows (id, document_id, workflow_type, current_stage)
SELECT 
  CONCAT('workflow_', id) as id,
  id as document_id,
  'manual' as workflow_type,
  'markdown-conversion' as current_stage
FROM documents;

-- Create initial stage records for existing documents
INSERT INTO document_processing_stages (id, document_id, stage_name, status)
SELECT 
  CONCAT(d.id, '_', stage.name) as id,
  d.id as document_id,
  stage.name as stage_name,
  'pending' as status
FROM documents d
CROSS JOIN (
  SELECT 'markdown-conversion' as name, 1 as order_num
  UNION SELECT 'markdown-optimizer', 2
  UNION SELECT 'chunker', 3  
  UNION SELECT 'fact-generator', 4
  UNION SELECT 'ingestor', 5
) stage;
```

### 2. Stage Dependencies Setup

```sql
-- Insert stage dependencies
INSERT INTO stage_dependencies (id, stage_name, depends_on_stage, is_required, execution_order) VALUES
('dep_1', 'markdown-conversion', NULL, true, 1),
('dep_2', 'markdown-optimizer', 'markdown-conversion', false, 2),
('dep_3', 'chunker', 'markdown-conversion', true, 3),
('dep_4', 'chunker_opt', 'markdown-optimizer', true, 3),
('dep_5', 'fact-generator', 'chunker', true, 4),
('dep_6', 'ingestor', 'fact-generator', true, 5),
('dep_7', 'ingestor', 'chunker', true, 5);
```

## API Integration Points

### 1. Stage Status Updates

```typescript
// Update stage status
interface StageStatusUpdate {
  documentId: string;
  stageName: string;
  status: 'pending' | 'in_progress' | 'completed' | 'failed' | 'skipped';
  startedAt?: Date;
  completedAt?: Date;
  errorMessage?: string;
}
```

### 2. File Storage

```typescript
// Store stage output file
interface StageOutputFile {
  documentId: string;
  stageName: string;
  fileType: string;
  filePath: string;
  fileSize: number;
  mimeType: string;
  checksum: string;
  metadata?: Record<string, any>;
}
```

## Service Layer Changes

### 1. Document Service Updates

```typescript
// lib/services/documentService.ts additions

export interface DocumentWithStages extends Document {
  processingWorkflow?: ProcessingWorkflow;
  stages?: DocumentProcessingStage[];
  outputFiles?: StageOutputFile[];
}

export async function getDocumentWithStages(id: string): Promise<DocumentWithStages | null> {
  // Implementation to fetch document with all stage information
}

export async function updateStageStatus(
  documentId: string, 
  stageName: string, 
  status: StageStatus,
  metadata?: Record<string, any>
): Promise<void> {
  // Implementation to update stage status
}

export async function storeStageOutputFile(
  documentId: string,
  stageName: string, 
  fileData: StageOutputFile
): Promise<void> {
  // Implementation to store stage output file reference
}
```

### 2. New Stage Service

```typescript
// lib/services/stageService.ts

export interface StageExecutionResult {
  success: boolean;
  outputFiles?: StageOutputFile[];
  error?: string;
  metadata?: Record<string, any>;
}

export async function executeStage(
  documentId: string,
  stageName: string,
  inputFiles?: string[]
): Promise<StageExecutionResult> {
  // Implementation to execute individual stage
}

export async function getStageStatus(
  documentId: string,
  stageName?: string
): Promise<DocumentProcessingStage[]> {
  // Implementation to get stage status
}

export async function getNextAvailableStage(
  documentId: string
): Promise<string | null> {
  // Implementation to determine next executable stage
}
```

## File Storage Strategy

### 1. File Organization

```
uploads/
├── documents/
│   └── {document-id}/
│       ├── original/
│       │   └── {filename}.{ext}
│       ├── stages/
│       │   ├── markdown-conversion/
│       │   │   └── {filename}.md
│       │   ├── markdown-optimizer/
│       │   │   └── {filename}.opt.md
│       │   ├── chunker/
│       │   │   └── {filename}.chunks.json
│       │   ├── fact-generator/
│       │   │   └── {filename}.facts.json
│       │   └── ingestor/
│       │       └── {filename}.ingestion.json
```

### 2. File Management Service

```typescript
// lib/services/fileService.ts

export async function storeStageFile(
  documentId: string,
  stageName: string,
  fileName: string,
  content: Buffer | string
): Promise<string> {
  // Implementation to store stage output file
}

export async function getStageFile(
  documentId: string,
  stageName: string,
  fileName: string
): Promise<Buffer | null> {
  // Implementation to retrieve stage output file
}

export async function listStageFiles(
  documentId: string,
  stageName?: string
): Promise<StageOutputFile[]> {
  // Implementation to list stage files
}
```

## Implementation Tasks

### Phase 1: Schema Implementation
- [ ] Create database migration scripts
- [ ] Update Prisma schema
- [ ] Run migrations on development database
- [ ] Test schema with sample data

### Phase 2: Service Layer
- [ ] Update documentService with stage support
- [ ] Create new stageService
- [ ] Implement fileService for stage outputs
- [ ] Add error handling and validation

### Phase 3: API Integration
- [ ] Update existing document APIs
- [ ] Create new stage management APIs
- [ ] Add file upload/download endpoints
- [ ] Implement webhook endpoints (if chosen)

### Phase 4: Testing
- [ ] Unit tests for service functions
- [ ] Integration tests for API endpoints
- [ ] Database migration testing
- [ ] Performance testing with large files

## Success Criteria

1. **Data Integrity**: All stage outputs are properly stored and retrievable
2. **Performance**: Database queries perform well with large numbers of documents
3. **Reliability**: No data loss during stage processing
4. **Scalability**: Schema supports future stage additions
5. **Migration**: Existing documents are properly migrated to new schema

## Risks and Mitigation

### Risk: Data Migration Complexity
- **Mitigation**: Comprehensive testing on copy of production data
- **Mitigation**: Rollback plan for failed migrations

### Risk: Storage Space Growth
- **Mitigation**: Implement file cleanup policies
- **Mitigation**: Consider file compression for large outputs

### Risk: Performance Impact
- **Mitigation**: Proper indexing strategy
- **Mitigation**: Query optimization and monitoring

## Next Steps

1. **Review Schema**: Get approval for proposed database changes
2. **Create Migrations**: Write Prisma migration scripts
3. **Update Types**: Update TypeScript interfaces
4. **Implement Services**: Create stage and file management services
5. **Testing**: Comprehensive testing of new schema

---

**Status**: Planning  
**Priority**: High  
**Estimated Effort**: 1-2 weeks  
**Dependencies**: Database access, Prisma setup